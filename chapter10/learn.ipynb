{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = 50  # 训练样本数\n",
    "x_train, _ = torch.sort(torch.rand(n_train) * 5)   # 排序后的训练样本\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "----------\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]]\n",
      "----------\n",
      "[[[1 2 3]]\n",
      "\n",
      " [[4 5 6]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2, 3), (1, 2, 3), (2, 1, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "# print(x,x[None,:],x[:,None])\n",
    "print(x)\n",
    "print('----------')\n",
    "print(x[None,:])\n",
    "print('----------')\n",
    "print(x[:,None])\n",
    "x.shape,x[None,:].shape,x[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen:\n",
      "3\n",
      "mask:\n",
      "tensor([[ True,  True, False],\n",
      "        [ True, False, False]])\n",
      "X:\n",
      "tensor([[1, 2, 0],\n",
      "        [4, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 0],\n",
       "        [4, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sequence_mask(X, valid_len, value):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    # [None,:]即给张量添加一维，shape=(2,3,5)-->[:,:,None,:]-->shape(2,3,1,5)\n",
    "    print('maxlen:')\n",
    "    print(maxlen)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None,:]<valid_len[:,None]  #有点看不懂\n",
    "    print('mask:')\n",
    "    print(mask)\n",
    "    X[~mask] = value\n",
    "    print('X:')\n",
    "    print(X)\n",
    "    return X\n",
    "\n",
    "X = torch.tensor([[1,2,3],[4,5,6]])\n",
    "valid_len = torch.tensor([2,1])\n",
    "sequence_mask(X,valid_len,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen:\n",
      "4\n",
      "mask:\n",
      "tensor([[ True,  True, False, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True, False, False, False],\n",
      "        [ True,  True,  True,  True]])\n",
      "X:\n",
      "tensor([[ 5.7515e-01,  4.5669e-01, -1.0000e+06, -1.0000e+06],\n",
      "        [ 4.7102e-01,  1.3428e-01,  8.2030e-01, -1.0000e+06],\n",
      "        [ 5.4356e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06],\n",
      "        [ 8.8438e-01,  3.3558e-02,  5.1651e-01,  3.2343e-01]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5296, 0.4704, 0.0000, 0.0000],\n",
       "         [0.3193, 0.2280, 0.4527, 0.0000]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3718, 0.1588, 0.2573, 0.2121]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1) # -1是最后一个维度\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "    \n",
    "\n",
    "X = torch.rand(2,2,4)\n",
    "valid_lens = torch.tensor([[2,3],[1,4]])\n",
    "masked_softmax(X, valid_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数准备\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3) #该函数作用是交换维度\n",
    "\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    '''缩放点积注意力'''\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度  ?\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen:\n",
      "6\n",
      "mask:\n",
      "tensor([[ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False]])\n",
      "X:\n",
      "tensor([[ 2.2885e-01,  2.2885e-01,  2.2885e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.2885e-01,  2.2885e-01,  2.2885e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.2885e-01,  2.2885e-01,  2.2885e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.2885e-01,  2.2885e-01,  2.2885e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-5.5845e-01, -5.5845e-01, -5.5845e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-5.5845e-01, -5.5845e-01, -5.5845e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-5.5845e-01, -5.5845e-01, -5.5845e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-5.5845e-01, -5.5845e-01, -5.5845e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-3.5379e-01, -3.5379e-01, -3.5379e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-3.5379e-01, -3.5379e-01, -3.5379e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-3.5379e-01, -3.5379e-01, -3.5379e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-3.5379e-01, -3.5379e-01, -3.5379e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.7768e-02,  2.7768e-02,  2.7768e-02, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.7768e-02,  2.7768e-02,  2.7768e-02, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.7768e-02,  2.7768e-02,  2.7768e-02, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.7768e-02,  2.7768e-02,  2.7768e-02, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-7.1173e-01, -7.1173e-01, -7.1173e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-7.1173e-01, -7.1173e-01, -7.1173e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-7.1173e-01, -7.1173e-01, -7.1173e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-7.1173e-01, -7.1173e-01, -7.1173e-01, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.2885e-01,  2.2885e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.2885e-01,  2.2885e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.2885e-01,  2.2885e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.2885e-01,  2.2885e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-5.5845e-01, -5.5845e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-5.5845e-01, -5.5845e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-5.5845e-01, -5.5845e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-5.5845e-01, -5.5845e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-3.5379e-01, -3.5379e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-3.5379e-01, -3.5379e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-3.5379e-01, -3.5379e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-3.5379e-01, -3.5379e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.7768e-02,  2.7768e-02, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.7768e-02,  2.7768e-02, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.7768e-02,  2.7768e-02, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [ 2.7768e-02,  2.7768e-02, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-7.1173e-01, -7.1173e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-7.1173e-01, -7.1173e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-7.1173e-01, -7.1173e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06],\n",
      "        [-7.1173e-01, -7.1173e-01, -1.0000e+06, -1.0000e+06, -1.0000e+06,\n",
      "         -1.0000e+06]], grad_fn=<AsStridedBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 100])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''多头注意力'''\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, \n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "            \n",
    "        # output的形状:(batch_size*num_heads，查询的个数，num_hiddens/num_heads)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "    \n",
    "\n",
    "\n",
    "num_hiddens, num_heads = 100,5\n",
    "attention = MultiHeadAttention(num_hiddens,num_hiddens,num_hiddens,num_hiddens,num_heads,0.5)\n",
    "attention.eval()\n",
    "batch_size, num_queries = 2, 4\n",
    "num_kvpairs, valid_lens = 6, torch.tensor([3,2])\n",
    "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
    "Y = torch.ones((batch_size, num_kvpairs, num_hiddens))\n",
    "attention(X,Y,Y,valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础操作\n",
    "def try_gpu(i=0):\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "# 函数准备\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3) #该函数作用是交换维度\n",
    "\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "# \n",
    "def sequence_mask(X, valid_len, value):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    # [None,:]即给张量添加一维，shape=(2,3,5)-->[:,:,None,:]-->shape(2,3,1,5)\n",
    "    #  mask 为内容为bool值的张量，通过比较判断bool值\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None,:]<valid_len[:,None]  \n",
    "    # ～对bool值取反\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "# \n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1) # -1是最后一个维度\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 网络类\n",
    "# \n",
    "class DotProductAttention(nn.Module):\n",
    "    '''缩放点积注意力'''\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度  ?\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "# \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    '''多头注意力'''\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, \n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，num_hiddens/num_heads)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "            \n",
    "        # output的形状:(batch_size*num_heads，查询的个数，num_hiddens/num_heads)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "# 不知道为什么叫基于位置的前馈神经网络\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    '''基于位置的前馈网络'''\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))       \n",
    "# \n",
    "class AddNorm(nn.Module):\n",
    "    '''残差连接和layernormal'''\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "    \n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y)+X)\n",
    "# \n",
    "class PositionalEncoding(nn.Module):\n",
    "    '''位置编码'''\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个足够长的P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1,1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:,:,0::2] = torch.sin(X)\n",
    "        self.P[:,:,1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "# \n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError\n",
    "#   \n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    # enc_outputs 为编码器输出\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError\n",
    "# \n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本接口\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    # enc_X为编码器输入，dec_X为解码器输入\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)\n",
    "\n",
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError\n",
    "# \n",
    "class EncoderBlock(nn.Module):\n",
    "    '''Transformer编码器中的任何层都不会改变其输入的形状'''\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, \n",
    "                                            num_heads, dropout, use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, ffn_num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        \n",
    "    def forward(self, X, valid_lens):       \n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "# \n",
    "class TransformerEncoder(Encoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size, \n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                                 EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "    \n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。    其实没太懂（但是感觉无伤大雅）\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights       #不理解这个是干吗用的,注意力权重可能要保存，后期画图啥的\n",
    "        return X\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            dec_valid_lens = torch.arange(1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # 编码器－解码器注意力。\n",
    "        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state\n",
    "    \n",
    "class TransformerDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            # 解码器自注意力权重\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            # “编码器－解码器”自注意力权重\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights\n",
    "# \n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    '''带屏蔽的Softmax交叉熵损失函数'''\n",
    "    # pred的形状：(batch_size,num_steps,vocab_size)\n",
    "    # label的形状：(batch_size,num_steps)\n",
    "    # valid_len的形状：(batch_size,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        # 所有预测词元掩码都为1\n",
    "        weights = torch.one_like(label)\n",
    "        # 无效位置为0\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "\n",
    "\n",
    "# 训练和预测\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    ''''''\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylavel='loss',xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_gard()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = d2l.concat([bos, Y[:, :-1]], 1)\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            d2l.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f}'\n",
    "          f'tokens/sec on {str(device)}')\n",
    "\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,device, \n",
    "                    save_attention_weights=False):\n",
    "    # set 'net' to eval mode for inference\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # Add the batch axis\n",
    "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoder(200,24,24,24,24,[100,24],24,24,8,2,0.5)\n",
    "encoder.eval()\n",
    "valid_lens = torch.tensor([3,2])\n",
    "encoder(torch.ones((2,100),dtype=torch.long),valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 1, 2],\n",
      "        [3, 4, 3, 4],\n",
      "        [1, 2, 1, 2],\n",
      "        [3, 4, 3, 4],\n",
      "        [1, 2, 1, 2],\n",
      "        [3, 4, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "y = x.repeat(3, 2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"187.07675pt\" height=\"172.346378pt\" viewBox=\"0 0 187.07675 172.346378\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-12-11T08:53:43.059398</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 172.346378 \nL 187.07675 172.346378 \nL 187.07675 0 \nL -0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 34.240625 59.190128 \nL 84.967898 59.190128 \nL 84.967898 8.462855 \nL 34.240625 8.462855 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#p528a388bcd)\">\n    <image xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAEcAAABHCAYAAABVsFofAAACgUlEQVR4nO2bTUtUURyH/+fqqJOpZRhhRIvc5M5V0KZ9rcKQFhUVtCgiWgTVJ4gIop20ah0RtMlVRC0igiCkoOjNCDIlw/F1HHXObdH6+fkB5vdsH84LDwcOc+felKe/lEFUOlBFW4VdbrJbXWTXN8AuImJ9jV2Z2VW6UF3cOYSu0LtpbRxH4DgCxxE4jsBxBCkvz/NVvrmOauPaaXSVew95xZKXi9oMu4iILK7rHbtRfRw5hG74/Tt0PjkCxxE4jsBxBI4jcBxBak5NiruVKV9NoCuOneUFO6o8p7qqI6J55yqveeoyD6yvsKt285xyNy2O4wgcR+A4AscROI4g5b+/8CpvPriFA4vRC+jmxk6iG3j2knezssAuIqKLr92odKIqZ76jS3sOoPPJETiOwHEEjiNwHIHjCFKuzeJVnl88woHFkRM8a32JXSf/Kt+KcvorurTvILrVc8fRdV3hX/M+OQLHETiOwHEEjiNwHIHjCNqjUWdbtLFbE0/0O7eh2rx5Hl3bdX5E8n/wJrvGKqrq3XF0SbyH6JMjcByB4wgcR+A4AscRtEdzg233dlT5MV+PxZkb6FJfL7tqD+8lImLXXnYrNZ63f5DHLf5B5ZMjcByB4wgcR+A4AscRpDw7Jb7U4z/nY6PBruDm5cIcj1uaZxcR5eRrXnL0Eo/7/Q1dvn+b55S7aXEcR+A4AscROI7AcQRJfnSv/vSvL7NTD+Z7+tlt9U6g+LA+//zE2xk+jG5i/zCP07tpbRxH4DgCxxE4jsBxBCnPz+BVXv74wAMH+bX4iIQmf36LrhgaEXOGfL1/aewout4nz9E13zzl/ejdtDaOI3AcgeMIHEfgOIJ/UeGQOX0s3vwAAAAASUVORK5CYII=\" id=\"image18332145e7\" transform=\"scale(1 -1) translate(0 -51.12)\" x=\"34.240625\" y=\"-8.070128\" width=\"51.12\" height=\"51.12\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m81830d686b\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m81830d686b\" x=\"36.776989\" y=\"59.190128\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m81830d686b\" x=\"62.140625\" y=\"59.190128\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_3\">\n      <defs>\n       <path id=\"m2756968df0\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m2756968df0\" x=\"34.240625\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(20.878125 14.798437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m2756968df0\" x=\"34.240625\" y=\"36.362855\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(20.878125 40.162074) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_3\">\n     <!-- Queries -->\n     <g transform=\"translate(14.798437 53.133523) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-51\" d=\"M 2522 4238 \nQ 1834 4238 1429 3725 \nQ 1025 3213 1025 2328 \nQ 1025 1447 1429 934 \nQ 1834 422 2522 422 \nQ 3209 422 3611 934 \nQ 4013 1447 4013 2328 \nQ 4013 3213 3611 3725 \nQ 3209 4238 2522 4238 \nz\nM 3406 84 \nL 4238 -825 \nL 3475 -825 \nL 2784 -78 \nQ 2681 -84 2626 -87 \nQ 2572 -91 2522 -91 \nQ 1538 -91 948 567 \nQ 359 1225 359 2328 \nQ 359 3434 948 4092 \nQ 1538 4750 2522 4750 \nQ 3503 4750 4090 4092 \nQ 4678 3434 4678 2328 \nQ 4678 1516 4351 937 \nQ 4025 359 3406 84 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-51\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"78.710938\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"142.089844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"203.613281\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"244.726562\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"272.509766\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"334.033203\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 34.240625 59.190128 \nL 34.240625 8.462855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 84.967898 59.190128 \nL 84.967898 8.462855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 34.240625 59.190128 \nL 84.967898 59.190128 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 34.240625 8.462855 \nL 84.967898 8.462855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 95.113352 59.190128 \nL 145.840625 59.190128 \nL 145.840625 8.462855 \nL 95.113352 8.462855 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#p5af85d2d2e)\">\n    <image xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAEcAAABHCAYAAABVsFofAAACmUlEQVR4nO2bPWsUURiFz52dGDVqxKwIhoAgMRJDGo0gflSihdiqhaBolcLKTkQkrWWUBUFBENSgjU0E0yg2FoJERfBzTVzJSDRqXEnc7B3/gOcQ0s552sN55+VhYDKTuyH+nslBiPevsghoaaFRcuA4zS6Wt/Bs+g2/HgAkJRrl059pFtZu4DND4JfT2xQbyxFYjsByBJYjsBxBiJOv+aM8q9Ji0tlNs/juOe/17OC9sTs0AwBs3sa71y/TLB2q8Jl+lC8NyxFYjsByBJYjsBxBUG/lg6u6aLFSe8aHirfg+OUt3yZdxjMAyOmqCO3reW+uzkd+naCZ7xyB5QgsR2A5AssRWI4gxZ+fNLxy6wJvruGPzuaju7yX1WiUHDrBewDig5s87NtJo7z+i1+zbzfP5DYFx3IEliOwHIHlCCxHEOLEK/qqmy80eHPhL43y2ZklLZOUN8o8ZpO8u6mXZvXTR2nWVrnBZ8ptCo7lCCxHYDkCyxFYjsByBKExdIr+nRP27ufFrh6eLW+jmTxksJV/dgAAtK7kc8VnktC/h8+s/+D76G2KjeUILEdgOQLLEViOIMTqOP/v/Dr+CSE+vsenpimNkv59NMuzT3wmgDhyjWalwfO8WOL7xPfjNPOdI7AcgeUILEdgOQLLEYQ49YEf76+J83vfMxolAwdp1hw+x5cpi3N9AJIjZ2gWn47y3nb+dSEXByl85wgsR2A5AssRWI7AcgQhzn7jj/KXT2gx6d1Fs1z8wi90dC5us//tMzLM9zl8kvce8l8Azo+O8ZmL2qqgWI7AcgSWI7AcgeUI5Fs5WlfwZmOeRre7B2h2rPqCZvnUR349AKG9zMPVHTxrzNGoeekszXznCCxHYDkCyxFYjsByBP8AzIicDhVlg2UAAAAASUVORK5CYII=\" id=\"image1b135cb3a3\" transform=\"scale(1 -1) translate(0 -51.12)\" x=\"95.113352\" y=\"-8.070128\" width=\"51.12\" height=\"51.12\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m81830d686b\" x=\"97.649716\" y=\"59.190128\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m81830d686b\" x=\"123.013352\" y=\"59.190128\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_3\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m2756968df0\" x=\"95.113352\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m2756968df0\" x=\"95.113352\" y=\"36.362855\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 95.113352 59.190128 \nL 95.113352 8.462855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 145.840625 59.190128 \nL 145.840625 8.462855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 95.113352 59.190128 \nL 145.840625 59.190128 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 95.113352 8.462855 \nL 145.840625 8.462855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_12\">\n    <path d=\"M 34.240625 134.790128 \nL 84.967898 134.790128 \nL 84.967898 84.062855 \nL 34.240625 84.062855 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#pa39cb22f40)\">\n    <image xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAEcAAABHCAYAAABVsFofAAACoklEQVR4nO2bPWuTURiGn3Ma26aWKI4WbUspUuyHoiIWHMTSwaCCWBwaBBcn8Qc4dVAHN6cg6KhDK4JgB9Hi56AOSm0FvxooxVhQE/ompFaTc/wF9z245r7Wi+ecw8WBN2nfuPrzmWgAv3MXUhae3ofOWlux6+6HyvcM4jkza9y4DJ0bO44H16t4z/3j2NHTNDmKQ1AcguIQFIegOAQXqmX4KK/ljsHB9LXreNX6X6hiYRE6v+8oXtPMrGMLdpVfZC4D1XTvCD4PP01zozgExSEoDkFxCIpDcKXR3fBRvnX2MZ6sVaCKaz/+6zDxxSz1PnsWy3QndvU6VGsTJ/B+9DRNjuIQFIegOATFISgOIZWZxN+8rYEfgeYcVOHRXej82Cm85OEs3s/MwpN7WA7sxXv2DkPXObQDz9HTNDmKQ1AcguIQFIegOISUdXVju7EOVSwV8VyS4Lkv89C5ngG8ppm5oYN4XXLW8HYOr5k7D51uDkFxCIpDUByC4hAUh6A4hJQVV6AMyx/w5Kf3ULVcuAJd/PYZu2IB72dmGzdvQdd+aQo6NzhKVsV/etHNISgOQXEIikNQHILiEFxYXoQvEiyNn4SDfXPkn/6bybt71TI7DnFm1t4B1Uz/AegmFp7hNTe1QaWbQ1AcguIQFIegOATFIbjGx1fwUR6LS3iyLY3d/Guo/JmL0CWn+YsEmWn868Dw8A50buQQdtu2Q6ebQ1AcguIQFIegOATFIbhQXsWP8vIqnkzwL+Nc3x7obnfhH/Lnvn/F+5lZJN/oY6UE3cIR/B7i8Bv8koFuDkFxCIpDUByC4hAUh5Ayj/vElw+g89lzeNU/v6GaLLzD+yU/8ZpmFmv4XcOQvwpdfgV/7Mj7Fuh0cwiKQ1AcguIQFIegOIR/8syWGKvdjyYAAAAASUVORK5CYII=\" id=\"image897ea4d7bb\" transform=\"scale(1 -1) translate(0 -51.12)\" x=\"34.240625\" y=\"-83.670128\" width=\"51.12\" height=\"51.12\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\">\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m81830d686b\" x=\"36.776989\" y=\"134.790128\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0 -->\n      <g transform=\"translate(33.595739 149.388565) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m81830d686b\" x=\"62.140625\" y=\"134.790128\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 5 -->\n      <g transform=\"translate(58.959375 149.388565) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- Key -->\n     <g transform=\"translate(50.539418 163.06669) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-4b\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 2694 \nL 3353 4666 \nL 4166 4666 \nL 1850 2491 \nL 4331 0 \nL 3500 0 \nL 1259 2247 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"60.576172\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"122.099609\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_6\">\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m2756968df0\" x=\"34.240625\" y=\"86.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(20.878125 90.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m2756968df0\" x=\"34.240625\" y=\"111.962855\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(20.878125 115.762074) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- Queries -->\n     <g transform=\"translate(14.798437 128.733523) rotate(-90) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-51\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"78.710938\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"142.089844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"203.613281\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"244.726562\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"272.509766\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"334.033203\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 34.240625 134.790128 \nL 34.240625 84.062855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 84.967898 134.790128 \nL 84.967898 84.062855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 34.240625 134.790128 \nL 84.967898 134.790128 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 34.240625 84.062855 \nL 84.967898 84.062855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n  <g id=\"axes_4\">\n   <g id=\"patch_17\">\n    <path d=\"M 95.113352 134.790128 \nL 145.840625 134.790128 \nL 145.840625 84.062855 \nL 95.113352 84.062855 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#p886116f45e)\">\n    <image xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAEcAAABHCAYAAABVsFofAAACoklEQVR4nO2bzUtUURyGf+fcUcYaMg0tiKiQiEikhQvb1CaClq0iwm1guBSkVlFBkWC1KBeCGhmuXEUQ9LGIIHKCgRgxBipSkT4mP8iaaZx7Tn/B+/4D8z7bh989l4cDZz7udWH5YzSET6ByrR3QxY2f0FlTM1Tp9CieM7PLQ5PQ3V7/ggfXv0MVfixB5+ndNDiKQ1AcguIQFIegOISMbW+FMjwawZN9p6DyB49CVx3shy47Oo7XM7Nb2RYs6zWo4kYZOte+BzrtHILiEBSHoDgExSEoDsGFxXn8rTwGPNmUhSodu4YX7D4GnT99Aa9nZuHdUyyrFey25fCah3uxo3fT4CgOQXEIikNQHILiEDIWyUle+YNdqQBdJb8AXW7wOr6bWhU7M4vPnkCXXLmL51Y+4Yvm2qDSziEoDkFxCIpDUByC4hBc/cEwPMt9/zCe3FyDKpTeQ+d7TuJrJhnszMzSLagG2g5BN/Z7EbpQeAmddg5BcQiKQ1AcguIQFIegOAQXNtfg55zwfJpMOqy6uqGL5RXs8m/wemaWDNzAsvYXqnTiJnT+zDns6N00OIpDUByC4hAUh6A4BFefvYd/sjhxFk9m8Z/zoZSHLs4+hM6fv4jXM7P46xue7erBc6v48f744S2+Jr2bBkdxCIpDUByC4hAUh+DC1yI8yi/tPw4H7xfx83lu1168YoLf/qN/+JuZNePnENnzi65jH54jH0m0cwiKQ1AcguIQFIegOASXFl/DozzOvcKTO3Zi145fyHed+FiNn+fxNc0sFuagywzdwXNb//BFidPOISgOQXEIikNQHILiEFx94io+ylfxy+rlmRfQdT6ewgvuPgBdWMA/dpuZ+SN9WAbyVmFIsSMv62vnEBSHoDgExSEoDkFxCP8Bh5qjRs2sWMMAAAAASUVORK5CYII=\" id=\"image849ffdcbb9\" transform=\"scale(1 -1) translate(0 -51.12)\" x=\"95.113352\" y=\"-83.670128\" width=\"51.12\" height=\"51.12\"/>\n   </g>\n   <g id=\"matplotlib.axis_7\">\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m81830d686b\" x=\"97.649716\" y=\"134.790128\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(94.468466 149.388565) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m81830d686b\" x=\"123.013352\" y=\"134.790128\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 5 -->\n      <g transform=\"translate(119.832102 149.388565) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_12\">\n     <!-- Key -->\n     <g transform=\"translate(111.412145 163.06669) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"60.576172\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"122.099609\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_8\">\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m2756968df0\" x=\"95.113352\" y=\"86.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m2756968df0\" x=\"95.113352\" y=\"111.962855\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 95.113352 134.790128 \nL 95.113352 84.062855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 145.840625 134.790128 \nL 145.840625 84.062855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 95.113352 134.790128 \nL 145.840625 134.790128 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 95.113352 84.062855 \nL 145.840625 84.062855 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n  <g id=\"axes_5\">\n   <g id=\"patch_22\">\n    <path d=\"M 152.815625 113.206491 \nL 156.973625 113.206491 \nL 156.973625 30.046491 \nL 152.815625 30.046491 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <image xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAAYAAAB0CAYAAACmJkOCAAAAyElEQVR4nL2WSw7DQAhDqTT3P2s33SR8egEekiOULLHMw0wyyqd+37LmOZbR1e1YJQhJQrWIsRXAixl7AiZPOQcK4SQgHFdCDmaswVmgVhX3Vit2+AsMdDhtdzPg3gmigwUdjp/B4lQqvB6coJxjL3kFtsKAJNzq9boKlx2ywFM5JM+Auz3p0kfBCT4w2vrACBRkOLbSk4fLjLZsdpL+GZwEbBXo6Ot2wigHOuSp3gjYv+sTA77NwQFH/sRxySvBVriSa29ccvwBAWMQUBD8h4AAAAAASUVORK5CYII=\" id=\"imagedda12471aa\" transform=\"scale(1 -1) translate(0 -83.52)\" x=\"152.64\" y=\"-29.52\" width=\"4.32\" height=\"83.52\"/>\n   <g id=\"matplotlib.axis_9\"/>\n   <g id=\"matplotlib.axis_10\">\n    <g id=\"ytick_9\">\n     <g id=\"line2d_17\">\n      <defs>\n       <path id=\"m254c60e04f\" d=\"M 0 0 \nL 3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m254c60e04f\" x=\"156.973625\" y=\"78.786941\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.2 -->\n      <g transform=\"translate(163.973625 82.586159) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m254c60e04f\" x=\"156.973625\" y=\"43.212123\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.4 -->\n      <g transform=\"translate(163.973625 47.011341) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"LineCollection_1\"/>\n   <g id=\"patch_23\">\n    <path d=\"M 152.815625 113.206491 \nL 154.894625 113.206491 \nL 156.973625 113.206491 \nL 156.973625 30.046491 \nL 154.894625 30.046491 \nL 152.815625 30.046491 \nL 152.815625 113.206491 \nz\n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p528a388bcd\">\n   <rect x=\"34.240625\" y=\"8.462855\" width=\"50.727273\" height=\"50.727273\"/>\n  </clipPath>\n  <clipPath id=\"p5af85d2d2e\">\n   <rect x=\"95.113352\" y=\"8.462855\" width=\"50.727273\" height=\"50.727273\"/>\n  </clipPath>\n  <clipPath id=\"pa39cb22f40\">\n   <rect x=\"34.240625\" y=\"84.062855\" width=\"50.727273\" height=\"50.727273\"/>\n  </clipPath>\n  <clipPath id=\"p886116f45e\">\n   <rect x=\"95.113352\" y=\"84.062855\" width=\"50.727273\" height=\"50.727273\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 250x250 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrices = torch.randn((2,2,10,10))\n",
    "# print(matrices)\n",
    "matrices = matrices.exp()/matrices.exp().sum(-1,keepdim=True)\n",
    "# print(matrices)\n",
    "d2l.show_heatmaps(matrices, xlabel='Key', ylabel='Queries')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af77ae0d45bf51025bcc6ee4d13239919a43d47d522bf9314842083250c0a012"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
